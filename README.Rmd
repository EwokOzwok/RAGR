---
title: "RAGR: Retrieval-Augmented Generation for PDFs"
output: github_document
---


# RAGR: Retrieval-Augmented Generation for PDF files

RAGR (**R**etrieval-**A**ugmented **G**eneration **R**eader) is an R Shiny app built with **shinyMobile** for the frontend and a **Flask + ExLlamaV2** backend. It allows users to interactively chat with the content of PDFs using **Retrieval-Augmented Generation (RAG)**.

The app is designed for **Windows users with WSL (Windows Subsystem for Linux)** for running the ExLlamaV2 backend.

## Features

* Upload PDFs up to **400 pages**.
* Chat interactively with your PDF content.
* Uses **ExLlamaV2** to generate responses based on uploaded content.
* **ShinyMobile** frontend for mobile-friendly interface.
* Each chat is treated as a new prompt; no chat history is stored.

*Upload your PDF by clicking or drag-and-drop.*

*Start chatting with your PDF after upload.*

## Quick Start / Usage

1. Open the app in your browser.
2. Click or drag-and-drop a PDF file (up to 400 pages).
3. Upon successful upload, click **"Start Chat"**.
4. Interact with your PDF using the chat dialog.
5. Refresh the page to upload a new PDF.

**Note:** Each chat session is independent; there is currently no persistent chat history.

## Installation Instructions (Windows + WSL)

### 1. Install WSL
(Ubuntu 22.04 recommended): [WSL Installation Guide](https://docs.microsoft.com/en-us/windows/wsl/install)

```bash
wsl.exe --install -d Ubuntu-22.04
```

### 2. Update / Upgrade Ubuntu

```bash
sudo apt update && sudo apt upgrade -y
```

### 3. Install Anaconda

```bash
wget https://repo.anaconda.com/archive/Anaconda3-2025.06-1-Linux-x86_64.sh
sha256sum Anaconda3-2025.06-1-Linux-x86_64.sh
bash Anaconda3-2025.06-1-Linux-x86_64.sh
source ~/.bashrc
conda --version
```

### 4. Install GCC 12

```bash
sudo apt update
sudo apt install build-essential gcc-12 g++-12
sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-12 60
sudo update-alternatives --install /usr/bin/g++ g++ /usr/bin/g++-12 60
gcc --version
```

### 5. Install CUDA Toolkit 12.8

```bash
wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-keyring_1.1-1_all.deb
sudo dpkg -i cuda-keyring_1.1-1_all.deb
sudo apt-get update
sudo apt-get -y install cuda-toolkit-12-8
```

### 6. Create Conda Environment and Install Dependencies

```bash
conda create -n vllm python=3.10
conda activate vllm
pip install https://github.com/turboderp-org/exllamav2/releases/download/v0.3.2/exllamav2-0.3.2+cu118.torch2.4.0-cp310-cp310-linux_x86_64.whl
pip install PyNaCl flask langchain-community
conda install transformers accelerate bitsandbytes
conda install -c conda-forge libstdcxx-ng
```

### 7. Set CUDA Environment Variables

```bash
nano ~/.bashrc
```

Add the following lines:
```bash
export CUDA_HOME=/usr/local/cuda-12.8
export PATH=$CUDA_HOME/bin:$PATH
export LD_LIBRARY_PATH=$CUDA_HOME/lib64:$LD_LIBRARY_PATH
```

Then run:
```bash
source ~/.bashrc
```

## Clone the Repository

```bash
git clone https://github.com/ewokozwok/ragr.git
cd ragr
```

## Running the App

### 1. Start the Flask backend

```bash
cd backend
python app.py
```

### 2. Start the ShinyMobile frontend

```r
remotes::install_github("EwokOzwok/RAGR")
RAGR::run_app()
```

### 3. Open your browser
Navigate to the URL provided by Shiny.

## Contributing

Contributions are welcome! Please fork the repository and submit pull requests.

## License

This project is licensed under the **Apache License 2.0**. See the LICENSE file for details.


## Screenshots

### Upload Your PDF
![Upload Interface](https://i.postimg.cc/sxK0XP1h/Upload.png)

### Upload Successful
![Chat Interface](https://i.postimg.cc/sDDNLL09/Start-Chat.png)  

### Interactive Chat
![Chat Interface](https://i.postimg.cc/9MhxYg79/Chat.png)  




